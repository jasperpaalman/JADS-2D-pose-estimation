{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "import methods as m\n",
    "import pickle\n",
    "import warnings\n",
    "import plotly as py\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_list_videos(vid_dir):\n",
    "    f = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(vid_dir):\n",
    "        f.extend(filenames)\n",
    "    return f\n",
    "\n",
    "\n",
    "def run_openpose(vid_dir,coord_location, openpose_location):\n",
    "    os.chdir(openpose_location)\n",
    "    for video in get_list_videos(vid_dir):\n",
    "        os.system(r'bin\\OpenPoseDemo.exe --video \"{0}\\{1}\" --write_json \"{2}\\{1}\"'.format(vid_dir, video, coord_location))\n",
    "\n",
    "        \n",
    "def create_total_feature_df(coord_df, video_number, return_df):\n",
    "    feature_df = to_feature_df(coord_df, video_number)\n",
    "    if return_df is None:\n",
    "        return_df = feature_df\n",
    "        print(return_df)\n",
    "    else:\n",
    "        return_df = return_df.append(feature_df)\n",
    "    return return_df\n",
    "\n",
    "\n",
    "def to_feature_df(coord_df, video_number):\n",
    "    \"\"\"\n",
    "    Gets a DataFrame of coordinates and turns this into features.\n",
    "    In this case, the standard deviation of movement vertically. Extension to also horizontally can be easily made in case this helps for discovering speed.\n",
    "\n",
    "    :param coord_df: A dataframe containing all relevant coördiantes observed in the video.\n",
    "\n",
    "    :return features_df: returns a dataframe containing standard deviations of all observed coordinates\n",
    "    \"\"\"\n",
    "    \n",
    "    #Set video number\n",
    "    coord_df['video'] = video_number\n",
    "    \n",
    "    #extract basic std deviation features of all joints\n",
    "    feature_df = coord_df.pivot_table(index=['video', 'Fragment'], columns='Point', values='y', aggfunc=np.std)\n",
    "  \n",
    "    #set video index\n",
    "    feature_df['video'] = feature_df.index\n",
    "\n",
    "    #Add value representing how much (in absoluut values) someone leaned forward\n",
    "    feature_df['Forward_leaning'] = m.forward_leaning_angle(coord_df)\n",
    "\n",
    "    return feature_df\n",
    "\n",
    "# def forward_leaning(coord_df):\n",
    "#     \"\"\"\n",
    "#     Create forward leaning feature to be used in classification. The forward leaning feature discribes to what extent a person\n",
    "#     leans forward. which could be an indicator of a good runner\n",
    "\n",
    "#     :param coord_df:  A dataframe containing all relevant coördiantes observed in the video.\n",
    "#     :return return_list: returns a list containing containing the absoluut distance that is leaned forward\n",
    "#     \"\"\"\n",
    "#     fragments = set(coord_df.Fragment)\n",
    "#     return_list = []\n",
    "\n",
    "#     for i in range(len(fragments)):\n",
    "#         fragment_df = coord_df[coord_df['Fragment'] == i+1]\n",
    "#         shoulder_df = fragment_df[fragment_df['Point'] == 'Right Shoulder']\n",
    "#         hip_df = fragment_df[fragment_df['Point'] == 'Right Hip']\n",
    "#         frames = set(fragment_df.Frame)\n",
    "#         temp_sum = 0\n",
    "#         frame_count = 0\n",
    "#         for j in range(len(frames)):\n",
    "#             difference = shoulder_df.iloc[j, 3] - hip_df.iloc[j, 3]\n",
    "#             #couldn't think of a smarter way to not take the nan values into account for the average\n",
    "#             if difference > 1:\n",
    "#                 frame_count += 1\n",
    "#                 temp_sum += difference\n",
    "#             if difference < -1:\n",
    "#                 frame_count += 1\n",
    "#                 temp_sum += difference\n",
    "#         return_list.append(abs(temp_sum / frame_count))\n",
    "#     return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def prepare_data_for_classification(vid_dir,coord_location, openpose_location):\n",
    "    #run_openpose(vid_dir,coord_location, openpose_location)\n",
    "    video_number = 1\n",
    "    return_df = None\n",
    "    for video in get_list_videos(vid_dir):\n",
    "        image_h, image_w, fps = m.determine_video_meta_data(r'{}\\{}'.format(vid_dir, video))\n",
    "\n",
    "        \n",
    "#        people_per_file = m.get_openpose_output(r'{}\\{}'.format(coord_location,video))\n",
    "        period_person_division = m.get_period_person_division(m.get_openpose_output(r'{}\\{}'.format(coord_location,video)), fps)\n",
    "        person_period_division = m.get_person_period_division(period_person_division)\n",
    "        \n",
    "        mean_x_per_person = m.get_mean_x_per_person(person_period_division)\n",
    "        \n",
    "        normalized_moved_distance_per_person = m.normalize_moved_distance_per_person(mean_x_per_person)\n",
    "        maximum_normalized_distance = max(normalized_moved_distance_per_person.values())\n",
    "        \n",
    "        movement_threshold = maximum_normalized_distance / 4\n",
    "        \n",
    "        moving_people = [key for key, value in normalized_moved_distance_per_person.items() if value > movement_threshold]\n",
    "        \n",
    "        \n",
    "        person_plottables_df = m.get_person_plottables_df(mean_x_per_person, moving_people)\n",
    "        \n",
    "        dbscan_subsets = m.get_dbscan_subsets(maximum_normalized_distance, person_plottables_df)\n",
    "        max_dbscan_subset = dbscan_subsets[\n",
    "            np.argmax([sum([len(person_period_division[person]) for person in subset]) for subset in dbscan_subsets])]\n",
    "        \n",
    "        plottable_people = m.determine_plottable_people(person_plottables_df, \n",
    "                                                      max_dbscan_subset, \n",
    "                                                      maximum_normalized_distance*4)\n",
    "        running_fragments, turning_fragments, fragments = m.get_running_and_turning_fragments(plottable_people, \n",
    "                                                                                                    mean_x_per_person, \n",
    "                                                                                                    person_plottables_df, \n",
    "                                                                                                    moving_people)\n",
    "        \n",
    "      #  coord_list = m.prepare_data_for_plotting(period_person_division, plottable_people, running_fragments)\n",
    "        coord_df = m.get_dataframe_from_coords(m.prepare_data_for_plotting(period_person_division, \n",
    "                                                                           plottable_people, \n",
    "                                                                           running_fragments))\n",
    "        return_df = create_total_feature_df(coord_df, video_number, return_df)\n",
    "\n",
    "        video_number +=1\n",
    "    return return_df\n",
    "    \n",
    "    \n",
    "        \n",
    "# extract_features(r'F:\\Dropbox\\TUe\\DS-E\\2017-2018\\JM0130 Data Entrepreneurship in Action II\\4. 2D_pose_estimation\\videos',\n",
    "#              r'F:\\Dropbox\\TUe\\DS-E\\2017-2018\\JM0130 Data Entrepreneurship in Action II\\4. 2D_pose_estimation\\coordinates',\n",
    "#             r'C:\\Users\\Herbert van Leeuwen\\Desktop\\openpose-1.2.1-win64-binaries\\openpose-1.2.1-win64-binaries')\n",
    "\n",
    "prepare_data_for_classification(r'C:\\Users\\herbe\\Dropbox\\TUe\\DS-E\\2017-2018\\JM0130 Data Entrepreneurship in Action II\\4. 2D_pose_estimation\\videos',\n",
    "             r'C:\\Users\\herbe\\Dropbox\\TUe\\DS-E\\2017-2018\\JM0130 Data Entrepreneurship in Action II\\4. 2D_pose_estimation\\coordinates',\n",
    "            r'C:\\Users\\Herbert van Leeuwen\\Desktop\\openpose-1.2.1-win64-binaries\\openpose-1.2.1-win64-binaries')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1.0,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1.0,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
