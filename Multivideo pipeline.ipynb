{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "import methods as m\n",
    "import pickle\n",
    "import warnings\n",
    "import plotly as py\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_list_videos(vid_dir):\n",
    "    f = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(vid_dir):\n",
    "        f.extend(filenames)\n",
    "    return f\n",
    "\n",
    "\n",
    "def run_openpose(vid_dir,coord_location, openpose_location):\n",
    "    os.chdir(openpose_location)\n",
    "    for video in get_list_videos(vid_dir):\n",
    "        os.system(r'bin\\OpenPoseDemo.exe --video \"{0}\\{1}\" --write_json \"{2}\\{1}\"'.format(vid_dir, video, coord_location))\n",
    "\n",
    "        \n",
    "def create_total_feature_df(coord_df, video_number, return_df, person_plottables, running_fragments, fragments, fps):\n",
    "    feature_df = to_feature_df(coord_df, video_number, person_plottables, running_fragments, fragments, fps)\n",
    "    if return_df is None:\n",
    "        return_df = feature_df\n",
    "#         print(return_df)\n",
    "    else:\n",
    "        return_df = return_df.append(feature_df)\n",
    "    return return_df\n",
    "\n",
    "\n",
    "def to_feature_df(coord_df, video_number, person_plottables, running_fragments, fragments, fps):\n",
    "    \"\"\"\n",
    "    Gets a DataFrame of coordinates and turns this into features.\n",
    "    In this case, the standard deviation of movement vertically. Extension to also horizontally can be easily made in case this helps for discovering speed.\n",
    "\n",
    "    :param coord_df: A dataframe containing all relevant coÃ¶rdiantes observed in the video.\n",
    "\n",
    "    :return features_df: returns a dataframe containing standard deviations of all observed coordinates\n",
    "    \"\"\"\n",
    "    \n",
    "    #Set video number\n",
    "    coord_df['video'] = video_number\n",
    "    \n",
    "    #extract basic std deviation features of all joints\n",
    "    feature_df = coord_df.pivot_table(index=['video', 'Fragment'], columns='Point', values='y', aggfunc=np.std)\n",
    "  \n",
    "    #set video index\n",
    "    feature_df['video'] = feature_df.index\n",
    "\n",
    "    #Add value representing how much (in absoluut values) someone leaned forward\n",
    "    feature_df['Forward_leaning'] = m.forward_leaning_angle(coord_df)\n",
    "    \n",
    "    feature_df['speed (km/h)'] = m.speed_via_distance(person_plottables, running_fragments, fragments, fps)\n",
    "    \n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def prepare_data_for_classification(vid_dir,coord_location, openpose_location):\n",
    "    #run_openpose(vid_dir,coord_location, openpose_location)\n",
    "    video_number = 1\n",
    "    return_df = None\n",
    "    for video in get_list_videos(vid_dir):\n",
    "        print(video)\n",
    "        image_h, image_w, fps = m.determine_video_meta_data(r'{}\\{}'.format(vid_dir, video))\n",
    "\n",
    "#        people_per_file = m.get_openpose_output(r'{}\\{}'.format(coord_location,video))\n",
    "        period_person_division = m.get_period_person_division(m.get_openpose_output(r'{}\\{}'.format(coord_location,video)), fps)\n",
    "        person_period_division = m.get_person_period_division(period_person_division)\n",
    "        \n",
    "        mean_x_per_person = m.get_mean_x_per_person(person_period_division)\n",
    "        \n",
    "        normalized_moved_distance_per_person = m.normalize_moved_distance_per_person(mean_x_per_person)\n",
    "        maximum_normalized_distance = max(normalized_moved_distance_per_person.values())\n",
    "        \n",
    "        movement_threshold = maximum_normalized_distance / 4\n",
    "        \n",
    "        moving_people = [key for key, value in normalized_moved_distance_per_person.items() if value > movement_threshold]\n",
    "        \n",
    "        \n",
    "        person_plottables_df = m.get_person_plottables_df(mean_x_per_person, moving_people)\n",
    "        \n",
    "        dbscan_subsets = m.get_dbscan_subsets(maximum_normalized_distance, person_plottables_df)\n",
    "        max_dbscan_subset = dbscan_subsets[\n",
    "            np.argmax([sum([len(person_period_division[person]) for person in subset]) for subset in dbscan_subsets])]\n",
    "        \n",
    "        plottable_people = m.determine_plottable_people(person_plottables_df,\n",
    "                                                     max_dbscan_subset,\n",
    "                                                     maximum_normalized_distance*4,\n",
    "                                                     maximum_normalized_distance**2)\n",
    "        \n",
    "        running_fragments, turning_fragments, fragments = m.get_running_and_turning_fragments(plottable_people,\n",
    "                                                                                                   mean_x_per_person,\n",
    "                                                                                                   person_plottables_df,\n",
    "                                                                                                   moving_people,\n",
    "                                                                                                   fps)\n",
    "        \n",
    "        coord_df = m.get_dataframe_from_coords(m.prepare_data_for_plotting(period_person_division, \n",
    "                                                                           plottable_people, \n",
    "                                                                           running_fragments))\n",
    "        \n",
    "        rotation_angle = m.get_rotation_angle(coord_df)\n",
    "\n",
    "        coord_df = m.process_coord_df(coord_df)\n",
    "\n",
    "        period_person_division = {period:{person: np.array([m.rotate((x,y), rotation_angle)+(z,) for x,y,z in coords])\n",
    "                                          for person, coords in period_dictionary.items()}\n",
    "                                          for period, period_dictionary in period_person_division.items()}\n",
    "\n",
    "        person_plottables, running_plottables, turning_plottables = \\\n",
    "                        m.get_plottables(period_person_division, plottable_people, running_fragments, turning_fragments)\n",
    "        \n",
    "        return_df = create_total_feature_df(coord_df, video_number, return_df, \n",
    "                                            person_plottables, running_fragments, fragments, fps)\n",
    "        video_number +=1\n",
    "    return return_df\n",
    "    \n",
    "    \n",
    "        \n",
    "df = prepare_data_for_classification(r'C:\\Users\\jaspe\\tf-openpose\\clips',\n",
    "             r'C:\\Users\\jaspe\\tf-openpose\\demo\\openpose-1.2.1-win64-binaries\\coordinates',\n",
    "            r'C:\\Users\\jaspe\\tf-openpose\\demo\\openpose-1.2.1-win64-binaries')\n",
    "\n",
    "# prepare_data_for_classification(r'C:\\Users\\herbe\\Dropbox\\TUe\\DS-E\\2017-2018\\JM0130 Data Entrepreneurship in Action II\\4. 2D_pose_estimation\\videos',\n",
    "#              r'C:\\Users\\herbe\\Dropbox\\TUe\\DS-E\\2017-2018\\JM0130 Data Entrepreneurship in Action II\\4. 2D_pose_estimation\\coordinates',\n",
    "#             r'C:\\Users\\Herbert van Leeuwen\\Desktop\\openpose-1.2.1-win64-binaries\\openpose-1.2.1-win64-binaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "features = list(set(df.columns[:-1]) - set(['video']))\n",
    "\n",
    "f,ax = plt.subplots(nrows=len(features)//3+1, ncols=3, figsize=(18,5*len(features)//3))\n",
    "\n",
    "for n, feature in enumerate(features):\n",
    "    sns.regplot(data=df, x=feature, y='speed (km/h)', ax=ax[n//3][n%3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('df_for_colin.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(df, open('df_for_colin.p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
