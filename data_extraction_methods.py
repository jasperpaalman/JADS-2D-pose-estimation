import json
from typing import Tuple, List, Dict

import numpy as np
import os
import cv2

from sklearn.metrics import mean_squared_error
from sklearn.metrics.pairwise import pairwise_distances
from math import sqrt

""""This module is meant to extract the data into usable formates to be used in the other modules"""

connections = [
    (1, 2), (1, 5), (2, 3), (3, 4), (5, 6), (6, 7), (1, 8),
    (8, 9), (9, 10), (1, 11), (11, 12), (12, 13), (1, 0),
    (0, 14), (14, 16), (0, 15), (15, 17), (2, 16), (5, 17)
]


def get_openpose_output(location: str) -> List[List[Dict]]:
    """
    This function extracts all information generated by the openpose demo and converts it into a list of dictionaries.

    :param location: is the location of the .json files outputted by OpenPoseDemo.
    :return: List of List of dictionaries. So a list of frames, each frame consists of a list of dictionaries in which
    all identified people in the video are described using the coordinates of the observed joints.
    """
    people_per_file = []
    # coordinate files are ordered, so we can iterate through the folder in which the coordinates are stores for a clip
    # each file corresponds to a frame
    for path, subdirs, files in os.walk(location):
        for filename in files:
            coord_path = os.path.join(path, filename)
            with open(coord_path) as f:
                people_per_file.append(json.load(f)['people'])
    return people_per_file


def determine_video_meta_data(file_path: str) -> Tuple:
    """"
    Extract the dimensions and frames per seconds from the video files

    :param file_path: Location of the video file
    :return: image_h image height, image_w image width, fps frames per second
    """
    cam = cv2.VideoCapture(file_path)
    ret_val, image = cam.read()
    image_h, image_w = image.shape[:2]  # getting clip resolution using opencv
    fps = cam.get(cv2.CAP_PROP_FPS)  # getting clip frames per second using opencv
    return image_h, image_w, fps


def rmse(a, b):
    """"
    Function which determines the rmse error between two sets of coordinates points

    :param a: coordinates a
    :param b: coordinates b
    :return: returns float
    """
    return sqrt(mean_squared_error(a, b))


def calc_center_coords_of_person(person_coords, used_joints: List[int]) -> Tuple:
    """"
    Using the coordinates all coordinates of a person identified in a specific frame the 'centre' of this person is calculated

    :param used_joints: List of all joints that are identified by OpenPose for this person
    :param person_coords: Coordinates belonging to person

    :returns cx, xy: centre x and centre y coordinates.
    """
    cx = np.mean(person_coords[used_joints, 0])  # center x-coordinate
    cy = np.mean(person_coords[used_joints, 1])  # center y-coordinate
    return cx, cy


def determine_rmse_threshold(person_coords, used_joints):
    """
    Using the centre coordinates of a identified person and the known used joints a rsme treshold is calculated

    :param used_joints: List of all joints that are identified by OpenPose for this person
    :param person_coords: Coordinates belonging to person
    :return rmse_threshold: a float value containing the rsme threshold
    """
    rmse_threshold = np.mean(
        pairwise_distances(np.array(calc_center_coords_of_person(person_coords, used_joints)).reshape(1, 2),
                           person_coords[used_joints, :2]))
    return rmse_threshold


def amount_of_frames_to_look_back(fps: float, frame: int) -> int:
    """
    Function that returns the amoount of frames that need be examined.

    :param fps: number of frames per second in current video
    :param frame: current frame in loop
    :return J: Number of frames to be examined
    """
    # number of frames to look back, set to 0.25 sec rather than number of frames
    max_frame_diff = int(fps // 4)
    if frame < max_frame_diff:
        j = frame
    else:
        j = max_frame_diff
    return j